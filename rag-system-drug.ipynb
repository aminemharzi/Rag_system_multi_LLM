{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:32:27.332010Z",
     "iopub.status.busy": "2025-01-10T08:32:27.331600Z",
     "iopub.status.idle": "2025-01-10T08:32:36.475673Z",
     "shell.execute_reply": "2025-01-10T08:32:36.474439Z",
     "shell.execute_reply.started": "2025-01-10T08:32:27.331964Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:32:36.477801Z",
     "iopub.status.busy": "2025-01-10T08:32:36.477290Z",
     "iopub.status.idle": "2025-01-10T08:32:41.084188Z",
     "shell.execute_reply": "2025-01-10T08:32:41.082701Z",
     "shell.execute_reply.started": "2025-01-10T08:32:36.477762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:32:41.086951Z",
     "iopub.status.busy": "2025-01-10T08:32:41.086582Z",
     "iopub.status.idle": "2025-01-10T08:32:47.573290Z",
     "shell.execute_reply": "2025-01-10T08:32:47.571746Z",
     "shell.execute_reply.started": "2025-01-10T08:32:41.086912Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=1583be64934b8cc97cf85589dfbcf5f76666e017f01ae27986d056ae000550ca\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:32:47.575920Z",
     "iopub.status.busy": "2025-01-10T08:32:47.575494Z",
     "iopub.status.idle": "2025-01-10T08:33:08.330054Z",
     "shell.execute_reply": "2025-01-10T08:33:08.328892Z",
     "shell.execute_reply.started": "2025-01-10T08:32:47.575878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 rows from CSV file.\n",
      "Created 100 rows after chunking.\n",
      "Processed data saved to processed_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "import uuid  # For generating UUIDs\n",
    "\n",
    "############################################\n",
    "# 1) Read data from CSV file\n",
    "############################################\n",
    "CSV_FILE_PATH = \"sample.csv\"  # Replace with your actual CSV file path\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "# Assuming the CSV has a column named \"context\" with text data to process\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "print(f\"Loaded {len(df)} rows from CSV file.\")\n",
    "\n",
    "############################################\n",
    "# 2) Process the DataFrame\n",
    "############################################\n",
    "# Create chunks of text from the \"context\" column\n",
    "records = []\n",
    "MAX_TOKENS = 3000  # Example token limit for chunking\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Safely get the context field\n",
    "    context = str(row.get(\"context\", \"\")).strip()  # Ensure the column name matches your CSV\n",
    "    if context:\n",
    "        # Create chunks by token size if necessary\n",
    "        words = context.split()\n",
    "        chunks = [\" \".join(words)]  # Modify as needed to split into smaller chunks\n",
    "        for chunk in chunks:\n",
    "            records.append({\n",
    "                \"chunk\": chunk,\n",
    "                \"uuid\": str(uuid.uuid4())  # Assign a unique UUID to each chunk\n",
    "            })\n",
    "\n",
    "# Convert to a Pandas DataFrame\n",
    "processed_df = pd.DataFrame(records)\n",
    "print(f\"Created {len(processed_df)} rows after chunking.\")\n",
    "\n",
    "# Replace NaN values with empty strings\n",
    "processed_df.fillna(\"\", inplace=True)\n",
    "\n",
    "############################################\n",
    "# 3) Save the processed data to CSV\n",
    "############################################\n",
    "output_csv_path = \"processed_data.csv\"\n",
    "processed_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Processed data saved to {output_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:08.331660Z",
     "iopub.status.busy": "2025-01-10T08:33:08.331195Z",
     "iopub.status.idle": "2025-01-10T08:33:08.347100Z",
     "shell.execute_reply": "2025-01-10T08:33:08.345762Z",
     "shell.execute_reply.started": "2025-01-10T08:33:08.331620Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brand Name: Bismuth Stibium, Generic Name: BIS...</td>\n",
       "      <td>0a8f5bf0-029b-4118-bb04-a386cc3277b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effective Time: 20240118, Effective Date: 2024...</td>\n",
       "      <td>df27e863-c982-483f-a595-ea35184a613d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brand Name: Omeprazole, Sodium bicarbonate, Ge...</td>\n",
       "      <td>3db0e559-ef0a-4495-87fc-0e0470183f67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brand Name: Diltiazem Hydrochloride Extended-R...</td>\n",
       "      <td>fb29119a-fd90-4251-94dc-a60f2081a4e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brand Name: FLUDROCORTISONE ACETATE, Generic N...</td>\n",
       "      <td>12049f60-5295-45cd-83f2-aba20e891ba5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  Brand Name: Bismuth Stibium, Generic Name: BIS...   \n",
       "1  Effective Time: 20240118, Effective Date: 2024...   \n",
       "2  Brand Name: Omeprazole, Sodium bicarbonate, Ge...   \n",
       "3  Brand Name: Diltiazem Hydrochloride Extended-R...   \n",
       "4  Brand Name: FLUDROCORTISONE ACETATE, Generic N...   \n",
       "\n",
       "                                   uuid  \n",
       "0  0a8f5bf0-029b-4118-bb04-a386cc3277b2  \n",
       "1  df27e863-c982-483f-a595-ea35184a613d  \n",
       "2  3db0e559-ef0a-4495-87fc-0e0470183f67  \n",
       "3  fb29119a-fd90-4251-94dc-a60f2081a4e5  \n",
       "4  12049f60-5295-45cd-83f2-aba20e891ba5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:08.348583Z",
     "iopub.status.busy": "2025-01-10T08:33:08.348210Z",
     "iopub.status.idle": "2025-01-10T08:33:08.851704Z",
     "shell.execute_reply": "2025-01-10T08:33:08.850535Z",
     "shell.execute_reply.started": "2025-01-10T08:33:08.348549Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brand Name: Bismuth Stibium, Generic Name: BISMUTH STIBIUM, Manufacturer Name: Uriel Pharmacy Inc., Product Type: HUMAN OTC DRUG, Route: TOPICAL, Effective Time: 20240122, Effective Date: 2024-01-22, Active Ingredient: Active Ingredients: 100 gm contains: 25 gm Allium sativa (Garlic) 1X, 25 gm Chelidonium (Greater celandine) 1X, 25 gm Curcuma (Turmeric) 1X, 25 gm Thuja (American arborvitae) 1X, 20 gm Bismuth 2X, 20 gm Stibium met. (Antimony) 2X, Warnings: Warnings: FOR EXTERNAL USE ONLY. Claims based on traditional homeopathic practice, not accepted medical evidence. Not FDA evaluated. Do not use if allergic to any ingredient. Consult a doctor before use for serious conditions, if conditions worsen or persist, or accidental ingestion occurs. If pregnant or nursing, consult a doctor before use. Avoid contact with eyes. Do not use if safety seal is broken or missing., Indications and Usage: Directions: FOR TOPICAL USE ONLY., Purpose: Use: Temporary relief of warts., Dosage and Administration: Apply once or twice daily to warts. Under age 2: Consult a doctor, Keep Out of Reach of Children: KEEP OUT OF REACH OF CHILDREN., Inactive Ingredient: Inactive Ingredients: White petrolatum, Lanolin, Mineral oil, Glyceryl monostearate, Sorbic acid, Tea tree oil, Grapefruit seed extract \"prepared using rhythmical processes\", Questions: Questions? Call 866.642.2858 Made with care by Uriel, East Troy, WI 53120 shopuriel.com Lot:, SPL Product Data Elements: Bismuth Stibium Bismuth Stibium PETROLATUM LANOLIN MINERAL OIL GLYCERYL MONOSTEARATE SORBIC ACID CITRUS PARADISI SEED GARLIC GARLIC CHELIDONIUM MAJUS CHELIDONIUM MAJUS TURMERIC TURMERIC THUJA OCCIDENTALIS WHOLE THUJA OCCIDENTALIS WHOLE BISMUTH BISMUTH ANTIMONY ANTIMONY TEA TREE OIL, Package Label Principal Display Panel: Bismuth Stibium Ointment'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:08.853720Z",
     "iopub.status.busy": "2025-01-10T08:33:08.853219Z",
     "iopub.status.idle": "2025-01-10T08:33:26.599872Z",
     "shell.execute_reply": "2025-01-10T08:33:26.598899Z",
     "shell.execute_reply.started": "2025-01-10T08:33:08.853665Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1592fc9e519748f3b591d662196486df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c929e3b578c4d8c92e3d1e094754de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92a30106aef4ba8a6aaecb180fe008f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27982f7af0748afb46253ba8f90a41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9563e5887704384bad6a85267e58841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d714c6e8ce10414d9f33766f98154c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0330efb1ec474e834b3ba453f05aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbbe8890b6c429882c425efcd619485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fdac30ad014924b024cf5749932005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5da03e5b0d24c4ba84da0a64ebc144e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50ac4826aeb4dd5a052d2bf148c333c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39dd0360c24473aa2882e14a816ce54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfedd6e7d87b4e5d919dd579bd6c2e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4996f3d41194adb8e589fb1ac0511e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1649c797dc43eb892fa5f55ea0e42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2856eb5f5c794ada8b32c81b6cdc7216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91856fd7dbe34046800f270c136e3525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f605c73bdf84aa4b6b090a182294d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec08238b9bb417c9ec8d7ffdff8291d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3348c5ef8be4da4b33d532a5fde678c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d346d95dd1e4b2aae3855551117b76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd6f267af7147e9a3ed51cbbc3e9243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1333d4213c34330927d1784098df8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466a35e061004a6280ae0760db03b3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7f4d629d0c4894b2b8830318679f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c7c8ef94b04f378aceaf2887906ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab8bfa92b974552a0f990c31cf394ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94efb4917cf14d39a083f6d33dbbbcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e112f4b9cb42fead1a4c1743831c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929ec8ef7c654fe880eff7689840f184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d126ca23c4b446195ac6ae87be7232d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540f5af247234a568f16b8facfc7ceb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7966288e40ac4728bccac5b4e222002a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfaf232d3de4e5aa05979d2c25ca4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becf54830166483b969e518827fc13c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c09c7921d649f9bcf4a2fb2bc0f26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2511d760db5f4df8aab57e96f6045ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15448d552b942ec966e84154ccc1b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe54239f42f41359af750c17e4119f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad50f93e72443c1a0d2705cde2b1339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c585d0f142a84d16b38a137c029c1990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d687b46c36574b4fab51b5b77ff19e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c190f6895d14ea2a5de903c359bb6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6925107fa35444ff9b9473dcf00e17e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72b368591ac4e5285aafb2f6f53cb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ca9c1f68d7435899fc9fa57ca90f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2912c028ffb243a69a88188f50839ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a4e15fa13d4af18063132174b082b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aa1dcf41bf4276909b0c07751218f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8587c3c6d7ca4e43acf775b8650973bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5106283d9564f368ee5602d2c9f3329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180c5c17b1b243859b1f071c26a275f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d05d5c53b34c2aa34aab0014147adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fc5c55ee694d5b94a4f4798e544be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417729f22b634d2a8d7c2adc50e0142b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62a1f80ae7b4a45b08072ada4b10633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e90f21c62224381807fe97f6a664161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc27c3d46484bd88157e44cfcff72eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0e701dd10e4074a0f758714a6bebc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036ece62a40b4afbb8f696c1a5d9797b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25b4a62313d4f2c81b437026797a133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce25f8c09a3e4234aa13519e4b3ad028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065a6947c14e4533a86bdda47ce6c49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3a806df64f49e08a27fc0fa25fa3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2617136605c4b49afd335ef080a2a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5321d89bd79b4f3b98b6746c0852004e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88522f15613049dca3313bb042e0515b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f6c2dfc00340d8b4836659627ad92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80af08ff333a40ad9868c7e023cd373e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161c43b6b6de4a59aba7b5efaa6610d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48337f214a2c45a8b90734909b524468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cd517cdae04a4eb92c53a5797485e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d3dc35dbcc4a3393301b8f9080b0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf764a6a9d0940e2a7b7b173321fb2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8e097e85a0402aac6908fe7a272be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c59db8fa1c4bd3934bf387e46e87fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112877211f854187a85e04e93a960fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6684d70e1164b5ca42f9b99c66023b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4c3041d32c4d7d8339911febbe1cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79cc0b66aeb4c78a2ecfa576819d5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050df03c054f4add845f3adf785fbbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e7c73d9fb446e08c43024da1218c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16654cde1f345039e5beb5dbcdd1036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95672c18dca34811b9863e8654fa820a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff44ed0e3fd449c9d88ce43e25e924a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa44efb364f54ae19bb2bece484c5b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e121c6cfad640d9a2bd2c67697f1075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedfbad101e846d3bbc7af2d854a2a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5e5a82511a4650a3f9d046aa569bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a8c260fa844e0098ab514e63eb09b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cdba76f52f49dfab48426226d5abc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec421c017c4b4ab1b2b4ff4095aeca1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17a086da1304e72a49c4ccc5a2fae3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94082008c9a54cbb82c19c53e50f83d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab81e59211cb44edb5bc6fee30c58a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aee56f5fba460eade75aa154d8dd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ea0f719a874435946a73e18e08b806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b00ea467af043b19f46861b6a571ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439ef8c63590443b94d1de4b8aa14dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a4d80d0992497cb5cb5a2fd6ae5e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739f0bc716ee4f6e8c365064f4402bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5571be3ebd4343438f9909ddb894c36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a52b26528042fb900d50112f62dd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55db3a96f3514b4db9c81609544c9ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a40bbd926d40a8bf5a0966766b07aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a546f6762454943862f06ce48e133a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99be85c527f48f18d99ebe7f324f35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531bc42f9dda4c7da6abd0ebc5944a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa69194f6a44a9da247d7a0ae6d0c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6b9615a53f480f9cf30d2bba7579e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15380d2fd7e04ab7a799949192afb617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for the context column\n",
    "processed_df['embeddings'] = processed_df['chunk'].apply(lambda x: model.encode(x).tolist())\n",
    "\n",
    "# Save embeddings for later use\n",
    "processed_df.to_parquet(\"data_with_embeddings_final.parquet\", index=False)\n",
    "print(\"Data with embeddings saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:26.603073Z",
     "iopub.status.busy": "2025-01-10T08:33:26.602759Z",
     "iopub.status.idle": "2025-01-10T08:33:26.611392Z",
     "shell.execute_reply": "2025-01-10T08:33:26.610412Z",
     "shell.execute_reply.started": "2025-01-10T08:33:26.603045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "embeddings = np.array(processed_df['embeddings'].tolist(), dtype='float32')\n",
    "\n",
    "# Create a FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(index, \"faiss_index_final.bin\")\n",
    "print(\"FAISS index saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:26.613546Z",
     "iopub.status.busy": "2025-01-10T08:33:26.612935Z",
     "iopub.status.idle": "2025-01-10T08:33:26.640558Z",
     "shell.execute_reply": "2025-01-10T08:33:26.639439Z",
     "shell.execute_reply.started": "2025-01-10T08:33:26.613505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "def generate_answer_with_context_t5(query, context):\n",
    "    model_name = \"t5-small\"  # or \"t5-base\", \"t5-large\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_length=100, num_beams=4, early_stopping=True)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:26.641798Z",
     "iopub.status.busy": "2025-01-10T08:33:26.641509Z",
     "iopub.status.idle": "2025-01-10T08:33:26.676438Z",
     "shell.execute_reply": "2025-01-10T08:33:26.675293Z",
     "shell.execute_reply.started": "2025-01-10T08:33:26.641774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def generate_answer_with_context_gpt2(query, context):\n",
    "    model_name = \"gpt2\"  # You can use \"gpt2-medium\", \"gpt2-large\" for larger models\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    # Increase max_length to a higher value, ensuring it's within the model's token limit\n",
    "    max_input_length = 1024  # Ensure this is within the model's max token limit\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n",
    "    \n",
    "    # Set max_new_tokens to control the length of the generated answer\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_new_tokens=150, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7)\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remove the prompt part from the output and return the answer\n",
    "    answer = generated_text[len(input_text):].strip()\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:26.677610Z",
     "iopub.status.busy": "2025-01-10T08:33:26.677352Z",
     "iopub.status.idle": "2025-01-10T08:33:26.684638Z",
     "shell.execute_reply": "2025-01-10T08:33:26.683539Z",
     "shell.execute_reply.started": "2025-01-10T08:33:26.677590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "def generate_answer_with_context_bert(query, context):\n",
    "    model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "    model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Prepare the input text for BERT\n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Print the tokenized input to check if the context and question are properly encoded\n",
    "    # print(\"Tokenized Input:\", inputs)\n",
    "\n",
    "    # Run the model to get start and end logits\n",
    "    outputs = model(**inputs)\n",
    "    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "    # Print the logits to see what the model is predicting\n",
    "    # print(\"Start Scores:\", start_scores)\n",
    "    # print(\"End Scores:\", end_scores)\n",
    "\n",
    "    # Get the most likely start and end positions\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "    # Check if the answer span is valid\n",
    "    if answer_start >= answer_end:\n",
    "        print(\"No valid answer found.\")\n",
    "        return \"No valid answer found.\"\n",
    "\n",
    "    # Decode the answer (removes [CLS], [SEP] tokens and gives you the answer span)\n",
    "    answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end], skip_special_tokens=True)\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:26.686202Z",
     "iopub.status.busy": "2025-01-10T08:33:26.685821Z",
     "iopub.status.idle": "2025-01-10T08:33:26.713412Z",
     "shell.execute_reply": "2025-01-10T08:33:26.712279Z",
     "shell.execute_reply.started": "2025-01-10T08:33:26.686163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizer\n",
    "import torch\n",
    "\n",
    "def generate_answer_with_context_distilbert(query, context):\n",
    "    model_name = \"distilbert-base-uncased-distilled-squad\"\n",
    "    model = DistilBertForQuestionAnswering.from_pretrained(model_name)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores) + 1\n",
    "    answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end])\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:26.715040Z",
     "iopub.status.busy": "2025-01-10T08:33:26.714598Z",
     "iopub.status.idle": "2025-01-10T08:33:26.728201Z",
     "shell.execute_reply": "2025-01-10T08:33:26.727180Z",
     "shell.execute_reply.started": "2025-01-10T08:33:26.714972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BloomForCausalLM, BloomTokenizerFast\n",
    "\n",
    "def generate_answer_with_context_bloom(query, context):\n",
    "    model_name = \"bigscience/bloom-560m\"\n",
    "    model = BloomForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = BloomTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    # Create the prompt\n",
    "    input_text = f\"Given the following context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=True)\n",
    "\n",
    "    # Generate the response\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_new_tokens=100)  # Control only new token generation\n",
    "\n",
    "    # Decode the generated tokens to text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_text = generated_text.split('Question: ')[-1]\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:33:26.729598Z",
     "iopub.status.busy": "2025-01-10T08:33:26.729301Z",
     "iopub.status.idle": "2025-01-10T08:35:23.330012Z",
     "shell.execute_reply": "2025-01-10T08:35:23.328873Z",
     "shell.execute_reply.started": "2025-01-10T08:33:26.729572Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c9d818e66346f2aec98a9124a4a749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb18452fbe349439763032b8e74a750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51aeb9ff06b24916976057d7db9c2815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e7c3d412e94199958485944fc11112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12d7bd2f3694da396852e612a3e43a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe257c54b574d0996adfaa9f4f67d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3b3298f249474ca9e73b479c8c5af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da0c78ed308495d8c7ff6816a8c5445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 model\n",
      "This product is a topical product that is used to treat wart, ulcers, and other skin conditions. It is also used for topical use to prevent the spread of bacteria, viruses, parasites, etc.\n",
      "What is the difference between Bistuth and Stobacillus?\n",
      "Bistutillus is an antibiotic that has been used in the treatment of many diseases. Bistsutilli are the most common bacteria in humans. They are found in many foods, including fruits, vegetables, nuts, seeds, grains, legumes, fish, eggs, dairy products, meat, poultry, seafood, milk, cheese, yogurt, ice cream, coffee, tea, cookies, cakes, candies, candy bars, soft drinks, snacks,\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302910ab3b934f32bb7cb034858a5598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3b30d60cb04b6c82353e097b6f6eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eec0aa3031b45edb0d48ac4f958b8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bfcb57d3194c9b8b6683487060da0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fade0030ec347a5a19937eaaa5e28d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74831ec6c56445e89eb0764c0e3fcfd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 model\n",
      ": Bismuth Stibium, Generic Name: BISMUTH STIBIUM, Manufacturer Name: Uriel Pharmacy Inc., Product Type: HUMAN OTC DRUG, Route: TOPICAL, Effective Time: 20240122, Effective Date: 2024-01-22, Active Ingredient: Active Ingredients: 100 gm contains: 25 gm Allium sativa (Garlic) 1X, 25 gm Chelid\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e86ed77d0b492dbcc3960b8ac2363d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad39cefe74034d31ac0819500982ab1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e05640fabb64ec1a4dcc12443411a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589535ac2b4e4010946f42236d85dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4ced8dc87a4a75acfcad632dc53428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99aa4a16777a4605a3abaccc91fb60ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7184130580e4327a72936ce7f7acda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244be48710074866a3769de0e5f4db42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f73dcc519c4e359e139b331b4ee574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e01353dda94720bd88465513762399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert model\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be373c551d47403ab83aeae851e81bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc1096fbff746fa86a6ef6dff061068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d6e702b4664ca2964417c63cc92432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91c6e3991c94a3aae4b150cdedab4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666e1125fb37405e8affb626fb0ba195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloom model\n",
      "What is Bismuth Stibium ?\n",
      "Answer: Bismuth Stibium is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index(\"faiss_index_final.bin\")\n",
    "\n",
    "# Example query\n",
    "query = \"Bismuth Stibium what is used from ?\"\n",
    "query_embedding = model.encode(query).astype('float32').reshape(1, -1)\n",
    "\n",
    "# Retrieve the top 5 most relevant contexts\n",
    "distances, indices = index.search(query_embedding, 5)\n",
    "\n",
    "# Extract the relevant contexts\n",
    "relevant_contexts = processed_df.iloc[indices[0]]['chunk'].tolist()\n",
    "\n",
    "# print('relevent context : ',relevant_contexts)\n",
    "context = relevant_contexts[0]\n",
    "\n",
    "# relevant_contexts = \"Brand Name: Bismuth Stibium, Generic Name: BISMUTH STIBIUM, Manufacturer Name: Uriel Pharmacy Inc.\"\n",
    "# query = \"What is Bismuth Stibium ?\"\n",
    "\n",
    "# For GPT-2\n",
    "generated_answer = generate_answer_with_context_gpt2(query, context)\n",
    "print(\"GPT-2 model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# For T5\n",
    "generated_answer = generate_answer_with_context_t5(query, context)\n",
    "print(\"T5 model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "# For BERT\n",
    "generated_answer = generate_answer_with_context_bert(query, context)\n",
    "print(\"BERT model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "# For DistilBERT\n",
    "generated_answer = generate_answer_with_context_distilbert(query, context)\n",
    "print(\"distilbert model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# For BLOOM\n",
    "generated_answer = generate_answer_with_context_bloom(query, context)\n",
    "print(\"bloom model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:19:13.703743Z",
     "iopub.status.busy": "2025-01-10T08:19:13.703211Z",
     "iopub.status.idle": "2025-01-10T08:19:14.469268Z",
     "shell.execute_reply": "2025-01-10T08:19:14.468116Z",
     "shell.execute_reply.started": "2025-01-10T08:19:13.703690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from rouge_score import rouge_scorer\n",
    "# from nltk.translate.bleu_score import sentence_bleu\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# def evaluate_answers(predicted_answers, reference_answers):\n",
    "#     # Initialize ROUGE scorer\n",
    "#     scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "#     results = {\n",
    "#         'rouge_scores': [],\n",
    "#         'bleu_scores': [],\n",
    "#         'exact_match': [],\n",
    "#         'f1_scores': []\n",
    "#     }\n",
    "    \n",
    "#     for pred, ref in zip(predicted_answers, reference_answers):\n",
    "#         # ROUGE scores\n",
    "#         rouge_scores = scorer.score(pred, ref)\n",
    "#         results['rouge_scores'].append(rouge_scores)\n",
    "        \n",
    "#         # BLEU score\n",
    "#         ref_tokens = [ref.split()]\n",
    "#         pred_tokens = pred.split()\n",
    "#         bleu = sentence_bleu(ref_tokens, pred_tokens)\n",
    "#         results['bleu_scores'].append(bleu)\n",
    "        \n",
    "#         # Exact Match\n",
    "#         exact_match = 1 if pred.lower().strip() == ref.lower().strip() else 0\n",
    "#         results['exact_match'].append(exact_match)\n",
    "        \n",
    "#         # F1 Score for word overlap\n",
    "#         pred_words = set(pred.lower().split())\n",
    "#         ref_words = set(ref.lower().split())\n",
    "#         precision = len(pred_words & ref_words) / len(pred_words) if pred_words else 0\n",
    "#         recall = len(pred_words & ref_words) / len(ref_words) if ref_words else 0\n",
    "#         f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "#         results['f1_scores'].append(f1)\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def calculate_average_metrics(results):\n",
    "#     avg_metrics = {\n",
    "#         'avg_rouge1': np.mean([s['rouge1'].fmeasure for s in results['rouge_scores']]),\n",
    "#         'avg_rouge2': np.mean([s['rouge2'].fmeasure for s in results['rouge_scores']]),\n",
    "#         'avg_rougeL': np.mean([s['rougeL'].fmeasure for s in results['rouge_scores']]),\n",
    "#         'avg_bleu': np.mean(results['bleu_scores']),\n",
    "#         'avg_exact_match': np.mean(results['exact_match']),\n",
    "#         'avg_f1': np.mean(results['f1_scores'])\n",
    "#     }\n",
    "#     return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:22:19.057638Z",
     "iopub.status.busy": "2025-01-10T08:22:19.057116Z",
     "iopub.status.idle": "2025-01-10T08:23:01.884568Z",
     "shell.execute_reply": "2025-01-10T08:23:01.883334Z",
     "shell.execute_reply.started": "2025-01-10T08:22:19.057601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GPT-2': {'avg_rouge1': 0.28723404255319157, 'avg_rouge2': 0.053763440860215055, 'avg_rougeL': 0.1595744680851064, 'avg_bleu': 0.32030896835479866, 'avg_exact_match': 0.0, 'avg_f1': 0.20437956204379565}, 'T5': {'avg_rouge1': 0.2835820895522388, 'avg_rouge2': 0.10606060606060606, 'avg_rougeL': 0.17910447761194026, 'avg_bleu': 0.0392018122070561, 'avg_exact_match': 0.0, 'avg_f1': 0.16822429906542055}, 'BERT': {'avg_rouge1': 0.0, 'avg_rouge2': 0.0, 'avg_rougeL': 0.0, 'avg_bleu': 0.0, 'avg_exact_match': 0.0, 'avg_f1': 0.0}, 'DistilBERT': {'avg_rouge1': 0.0, 'avg_rouge2': 0.0, 'avg_rougeL': 0.0, 'avg_bleu': 0.0, 'avg_exact_match': 0.0, 'avg_f1': 0.0}, 'BLOOM': {'avg_rouge1': 0.24175824175824176, 'avg_rouge2': 0.044444444444444446, 'avg_rougeL': 0.2087912087912088, 'avg_bleu': 0.035371965931008, 'avg_exact_match': 0.0, 'avg_f1': 0.17582417582417584}}\n"
     ]
    }
   ],
   "source": [
    "# test_data = [\n",
    "#     {\n",
    "#         'question': 'What is Bismuth Stibium?',\n",
    "#         'context': context,  # Your retrieved context\n",
    "#         'reference_answer': 'Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.'  # Ground truth answer\n",
    "#     },\n",
    "#     # Add more test cases\n",
    "# ]\n",
    "\n",
    "# # Evaluate each model\n",
    "# models = {\n",
    "#     'GPT-2': generate_answer_with_context_gpt2,\n",
    "#     'T5': generate_answer_with_context_t5,\n",
    "#     'BERT': generate_answer_with_context_bert,\n",
    "#     'DistilBERT': generate_answer_with_context_distilbert,\n",
    "#     'BLOOM': generate_answer_with_context_bloom\n",
    "# }\n",
    "\n",
    "# def evaluate_all_models(test_data, models):\n",
    "#     results = {}\n",
    "    \n",
    "#     for model_name, model_func in models.items():\n",
    "#         predicted_answers = []\n",
    "#         reference_answers = []\n",
    "        \n",
    "#         for test_case in test_data:\n",
    "#             pred_answer = model_func(test_case['question'], test_case['context'])\n",
    "#             predicted_answers.append(pred_answer)\n",
    "#             reference_answers.append(test_case['reference_answer'])\n",
    "        \n",
    "#         # Evaluate answers\n",
    "#         eval_results = evaluate_answers(predicted_answers, reference_answers)\n",
    "#         avg_metrics = calculate_average_metrics(eval_results)\n",
    "#         results[model_name] = avg_metrics\n",
    "#     print(results)\n",
    "#     return results\n",
    "\n",
    "# # Run evaluation\n",
    "# evaluation_results = evaluate_all_models(test_data, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:24:09.465180Z",
     "iopub.status.busy": "2025-01-10T08:24:09.464707Z",
     "iopub.status.idle": "2025-01-10T08:24:09.472366Z",
     "shell.execute_reply": "2025-01-10T08:24:09.470982Z",
     "shell.execute_reply.started": "2025-01-10T08:24:09.465146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import psutil\n",
    "# import torch\n",
    "\n",
    "# def measure_performance(func, *args):\n",
    "#     # Start measuring time and memory\n",
    "#     start_time = time.time()\n",
    "#     start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # Memory in MB\n",
    "    \n",
    "#     # Run the function\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "#     result = func(*args)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     end_time = time.time()\n",
    "#     end_memory = psutil.Process().memory_info().rss / 1024 / 1024\n",
    "    \n",
    "#     metrics = {\n",
    "#         'execution_time': end_time - start_time,\n",
    "#         'memory_usage': end_memory - start_memory,\n",
    "#     }\n",
    "    \n",
    "#     if torch.cuda.is_available():\n",
    "#         metrics['gpu_memory'] = torch.cuda.max_memory_allocated() / 1024 / 1024  # MB\n",
    "    \n",
    "#     return result, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:24:16.418211Z",
     "iopub.status.busy": "2025-01-10T08:24:16.417782Z",
     "iopub.status.idle": "2025-01-10T08:24:16.424844Z",
     "shell.execute_reply": "2025-01-10T08:24:16.423607Z",
     "shell.execute_reply.started": "2025-01-10T08:24:16.418180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def create_evaluation_report(evaluation_results, performance_metrics):\n",
    "#     import pandas as pd\n",
    "    \n",
    "#     # Create DataFrame for quality metrics\n",
    "#     quality_df = pd.DataFrame(evaluation_results).round(4)\n",
    "    \n",
    "#     # Create DataFrame for performance metrics\n",
    "#     performance_df = pd.DataFrame(performance_metrics).round(4)\n",
    "    \n",
    "#     # Generate report\n",
    "#     report = f\"\"\"RAG System Evaluation Report\n",
    "    \n",
    "# Quality Metrics:\n",
    "# {quality_df.to_string()}\n",
    "\n",
    "# Performance Metrics:\n",
    "# {performance_df.to_string()}\n",
    "\n",
    "# Summary:\n",
    "# - Best model for ROUGE-1: {quality_df.loc['avg_rouge1'].idxmax()} ({quality_df.loc['avg_rouge1'].max():.4f})\n",
    "# - Best model for F1: {quality_df.loc['avg_f1'].idxmax()} ({quality_df.loc['avg_f1'].max():.4f})\n",
    "# - Fastest model: {performance_df.loc['execution_time'].idxmin()} ({performance_df.loc['execution_time'].min():.4f}s)\n",
    "# \"\"\"\n",
    "#     return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T08:35:32.163097Z",
     "iopub.status.busy": "2025-01-10T08:35:32.162716Z",
     "iopub.status.idle": "2025-01-10T08:36:16.484800Z",
     "shell.execute_reply": "2025-01-10T08:36:16.483628Z",
     "shell.execute_reply.started": "2025-01-10T08:35:32.163068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\n",
      "Evaluating GPT-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-2 Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: This product is a topical product that is used to treat wart, ulcers, and other skin conditions. It is also used for topical use to prevent or treat other conditions such as acne, psoriasis, eczema, rashes, dry skin, skin cancer, etc.\n",
      "What is the difference between Bistuth and Bactulose? BISTUTH is an antiseptic that has been used in the treatment of psoriatic ulcerative colitis, acne vulgaris, dermatitis and psorsitis. BACTULOSE is another topical antisera that was used as a treatment for psorectal ulicosis. The difference is that BIS is not a preservative. This is because B\n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.28723404255319157, 'rouge2': 0.053763440860215055, 'rougeL': 0.1595744680851064, 'bleu': 0.32030896835479866, 'exact_match': 0, 'f1': 0.20437956204379565, 'execution_time': 8.7143075466156}\n",
      "\n",
      "Evaluating T5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T5 Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: : Bismuth Stibium, Generic Name: BISMUTH STIBIUM, Manufacturer Name: Uriel Pharmacy Inc., Product Type: HUMAN OTC DRUG, Route: TOPICAL, Effective Time: 20240122, Effective Date: 2024-01-22, Active Ingredient: Active Ingredients: 100 gm contains: 25 gm Allium sativa (Garlic) 1X, 25 gm Chelid\n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.2835820895522388, 'rouge2': 0.10606060606060606, 'rougeL': 0.17910447761194026, 'bleu': 0.0392018122070561, 'exact_match': 0, 'f1': 0.16822429906542055, 'execution_time': 5.089862585067749}\n",
      "\n",
      "Evaluating BERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: \n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0, 'bleu': 0, 'exact_match': 0, 'f1': 0, 'execution_time': 4.387006521224976}\n",
      "\n",
      "Evaluating DistilBERT...\n",
      "\n",
      "DistilBERT Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: \n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0, 'bleu': 0, 'exact_match': 0, 'f1': 0, 'execution_time': 1.1305692195892334}\n",
      "\n",
      "Evaluating BLOOM...\n",
      "\n",
      "BLOOM Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: What is Bismuth Stibium?\n",
      "Answer: Bismuth Stibium is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived\n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.24175824175824176, 'rouge2': 0.044444444444444446, 'rougeL': 0.2087912087912088, 'bleu': 0.035371965931008, 'exact_match': 0, 'f1': 0.17582417582417584, 'execution_time': 23.927987575531006}\n",
      "\n",
      "Final Evaluation Results:\n",
      "                 GPT-2      T5   BERT  DistilBERT    BLOOM\n",
      "rouge1          0.2872  0.2836  0.000      0.0000   0.2418\n",
      "rouge2          0.0538  0.1061  0.000      0.0000   0.0444\n",
      "rougeL          0.1596  0.1791  0.000      0.0000   0.2088\n",
      "bleu            0.3203  0.0392  0.000      0.0000   0.0354\n",
      "exact_match     0.0000  0.0000  0.000      0.0000   0.0000\n",
      "f1              0.2044  0.1682  0.000      0.0000   0.1758\n",
      "execution_time  8.7143  5.0899  4.387      1.1306  23.9280\n",
      "\n",
      "Results saved to 'rag_evaluation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')  # Required for BLEU score\n",
    "\n",
    "# First, let's define our test dataset with some sample questions and reference answers\n",
    "test_data = [\n",
    "    {\n",
    "        'question': 'What is Bismuth Stibium?',\n",
    "        'context': context,  # Your existing context\n",
    "        'reference_answer': 'Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.'\n",
    "    },\n",
    "    # Add more test cases if you have them\n",
    "]\n",
    "\n",
    "# Keep your existing model functions\n",
    "models = {\n",
    "    'GPT-2': generate_answer_with_context_gpt2,\n",
    "    'T5': generate_answer_with_context_t5,\n",
    "    'BERT': generate_answer_with_context_bert,\n",
    "    'DistilBERT': generate_answer_with_context_distilbert,\n",
    "    'BLOOM': generate_answer_with_context_bloom\n",
    "}\n",
    "\n",
    "def evaluate_single_answer(predicted, reference):\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # ROUGE scores\n",
    "    rouge_scores = scorer.score(predicted, reference)\n",
    "    \n",
    "    # BLEU score\n",
    "    ref_tokens = [reference.split()]\n",
    "    pred_tokens = predicted.split()\n",
    "    try:\n",
    "        bleu = sentence_bleu(ref_tokens, pred_tokens)\n",
    "    except:\n",
    "        bleu = 0\n",
    "    \n",
    "    # Exact Match\n",
    "    exact_match = 1 if predicted.lower().strip() == reference.lower().strip() else 0\n",
    "    \n",
    "    # F1 Score\n",
    "    pred_words = set(predicted.lower().split())\n",
    "    ref_words = set(reference.lower().split())\n",
    "    \n",
    "    precision = len(pred_words & ref_words) / len(pred_words) if pred_words else 0\n",
    "    recall = len(pred_words & ref_words) / len(ref_words) if ref_words else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "    \n",
    "    return {\n",
    "        'rouge1': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL': rouge_scores['rougeL'].fmeasure,\n",
    "        'bleu': bleu,\n",
    "        'exact_match': exact_match,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "def evaluate_model(model_name, model_func, test_data):\n",
    "    all_metrics = []\n",
    "    execution_times = []\n",
    "    \n",
    "    for test_case in test_data:\n",
    "        # Measure execution time\n",
    "        start_time = time.time()\n",
    "        predicted_answer = model_func(test_case['question'], test_case['context'])\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = evaluate_single_answer(predicted_answer, test_case['reference_answer'])\n",
    "        metrics['execution_time'] = execution_time\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        # Print individual results\n",
    "        print(f\"\\n{model_name} Results for Question: {test_case['question']}\")\n",
    "        print(f\"Predicted Answer: {predicted_answer}\")\n",
    "        print(f\"Reference Answer: {test_case['reference_answer']}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_metrics = {\n",
    "        metric: np.mean([m[metric] for m in all_metrics])\n",
    "        for metric in all_metrics[0].keys()\n",
    "    }\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Run evaluation for all models\n",
    "results = {}\n",
    "for model_name, model_func in models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    try:\n",
    "        results[model_name] = evaluate_model(model_name, model_func, test_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Create final report\n",
    "df_results = pd.DataFrame(results).round(4)\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(df_results)\n",
    "\n",
    "# Save results to CSV\n",
    "df_results.to_csv('rag_evaluation_results.csv')\n",
    "print(\"\\nResults saved to 'rag_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T07:59:26.327233Z",
     "iopub.status.busy": "2025-01-10T07:59:26.326795Z",
     "iopub.status.idle": "2025-01-10T07:59:27.464280Z",
     "shell.execute_reply": "2025-01-10T07:59:27.463117Z",
     "shell.execute_reply.started": "2025-01-10T07:59:26.327203Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model\n",
      "dosage\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "# import torch\n",
    "\n",
    "# def generate_answer_with_context_bert(query, context):\n",
    "#     model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "#     model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "#     tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "#     # Prepare the input text for BERT\n",
    "#     input_text = f\"Context: {context}\\nQuestion: {query}\"\n",
    "#     inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "#     # Run the model to get start and end logits\n",
    "#     outputs = model(**inputs)\n",
    "#     start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "#     # Debug: Print the logits to understand where the model is looking for the answer\n",
    "#     # print(\"Start Scores:\", start_scores)\n",
    "#     # print(\"End Scores:\", end_scores)\n",
    "\n",
    "#     # Get the most likely start and end positions\n",
    "#     answer_start = torch.argmax(start_scores)\n",
    "#     answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "#     # Check if the answer span is valid (ensuring answer_start < answer_end)\n",
    "#     if answer_start >= answer_end:\n",
    "#         print(\"No valid answer found.\")\n",
    "#         return \"No valid answer found.\"\n",
    "\n",
    "#     # Decode the answer (removes [CLS], [SEP] tokens and gives you the answer span)\n",
    "#     answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end], skip_special_tokens=True)\n",
    "    \n",
    "#     # Check if the answer is meaningful or just a part of the question\n",
    "#     if answer.lower() == query.lower():\n",
    "#         print(\"The model returned the question itself, no valid answer found.\")\n",
    "#         return \"No valid answer found.\"\n",
    "\n",
    "#     return answer\n",
    "\n",
    "# # Example of running the function with different inputs\n",
    "# query = \"What is the dosage for the drug?\"\n",
    "# context = \"Brand Name: Bismuth Stibium, Generic Name: BISMUTH STIBIUM, Manufacturer Name: Uriel Pharmacy Inc., Directions: Apply once or twice daily to warts.\"\n",
    "# generated_answer = generate_answer_with_context_bert(query, context)\n",
    "\n",
    "# print(\"BERT model\")\n",
    "# print(generated_answer)\n",
    "# print(\"------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6444752,
     "sourceId": 10401121,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
