{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:36:37.375244Z",
     "iopub.status.busy": "2025-01-11T17:36:37.374926Z",
     "iopub.status.idle": "2025-01-11T17:36:44.953957Z",
     "shell.execute_reply": "2025-01-11T17:36:44.952559Z",
     "shell.execute_reply.started": "2025-01-11T17:36:37.375219Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:36:44.956093Z",
     "iopub.status.busy": "2025-01-11T17:36:44.955734Z",
     "iopub.status.idle": "2025-01-11T17:36:49.093477Z",
     "shell.execute_reply": "2025-01-11T17:36:49.092109Z",
     "shell.execute_reply.started": "2025-01-11T17:36:44.956063Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: replicate in /usr/local/lib/python3.10/dist-packages (1.0.4)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.1)\n",
      "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.9.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.12.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.23.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:36:49.096160Z",
     "iopub.status.busy": "2025-01-11T17:36:49.095801Z",
     "iopub.status.idle": "2025-01-11T17:36:53.699947Z",
     "shell.execute_reply": "2025-01-11T17:36:53.698255Z",
     "shell.execute_reply.started": "2025-01-11T17:36:49.096131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:36:53.702417Z",
     "iopub.status.busy": "2025-01-11T17:36:53.701965Z",
     "iopub.status.idle": "2025-01-11T17:37:00.350250Z",
     "shell.execute_reply": "2025-01-11T17:37:00.348574Z",
     "shell.execute_reply.started": "2025-01-11T17:36:53.702372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=3d7fd7f06dfea66e9605ca486694841929bb2908aacc628ba3ce0580533006ee\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:00.352283Z",
     "iopub.status.busy": "2025-01-11T17:37:00.351836Z",
     "iopub.status.idle": "2025-01-11T17:37:23.008259Z",
     "shell.execute_reply": "2025-01-11T17:37:23.006884Z",
     "shell.execute_reply.started": "2025-01-11T17:37:00.352249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 rows from CSV file.\n",
      "Created 100 rows after chunking.\n",
      "Processed data saved to processed_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "import uuid  # For generating UUIDs\n",
    "\n",
    "############################################\n",
    "# 1) Read data from CSV file\n",
    "############################################\n",
    "CSV_FILE_PATH = \"/kaggle/input/drug-label-dataset/sample.csv\"  # Replace with your actual CSV file path\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "# Assuming the CSV has a column named \"context\" with text data to process\n",
    "df = pd.read_csv(CSV_FILE_PATH)\n",
    "print(f\"Loaded {len(df)} rows from CSV file.\")\n",
    "\n",
    "############################################\n",
    "# 2) Process the DataFrame\n",
    "############################################\n",
    "# Create chunks of text from the \"context\" column\n",
    "records = []\n",
    "MAX_TOKENS = 3000  # Example token limit for chunking\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Safely get the context field\n",
    "    context = str(row.get(\"context\", \"\")).strip()  # Ensure the column name matches your CSV\n",
    "    if context:\n",
    "        # Create chunks by token size if necessary\n",
    "        words = context.split()\n",
    "        chunks = [\" \".join(words)]  # Modify as needed to split into smaller chunks\n",
    "        for chunk in chunks:\n",
    "            records.append({\n",
    "                \"chunk\": chunk,\n",
    "                \"uuid\": str(uuid.uuid4())  # Assign a unique UUID to each chunk\n",
    "            })\n",
    "\n",
    "# Convert to a Pandas DataFrame\n",
    "processed_df = pd.DataFrame(records)\n",
    "print(f\"Created {len(processed_df)} rows after chunking.\")\n",
    "\n",
    "# Replace NaN values with empty strings\n",
    "processed_df.fillna(\"\", inplace=True)\n",
    "\n",
    "############################################\n",
    "# 3) Save the processed data to CSV\n",
    "############################################\n",
    "output_csv_path = \"processed_data.csv\"\n",
    "processed_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Processed data saved to {output_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:23.010031Z",
     "iopub.status.busy": "2025-01-11T17:37:23.009622Z",
     "iopub.status.idle": "2025-01-11T17:37:23.025257Z",
     "shell.execute_reply": "2025-01-11T17:37:23.024144Z",
     "shell.execute_reply.started": "2025-01-11T17:37:23.010000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brand Name: Bismuth Stibium, Generic Name: BIS...</td>\n",
       "      <td>a1f0d44f-d419-413e-b797-00dac391d9f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effective Time: 20240118, Effective Date: 2024...</td>\n",
       "      <td>7f3ffb22-9de3-4da0-8e3f-a7bfd0559439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brand Name: Omeprazole, Sodium bicarbonate, Ge...</td>\n",
       "      <td>f77124f7-7b23-4f9d-a60d-ce0b537aca7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brand Name: Diltiazem Hydrochloride Extended-R...</td>\n",
       "      <td>948f7a14-2725-4f12-8159-c75761e677ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brand Name: FLUDROCORTISONE ACETATE, Generic N...</td>\n",
       "      <td>e2921711-6b00-431f-bcbd-f2b7aa8252ed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  Brand Name: Bismuth Stibium, Generic Name: BIS...   \n",
       "1  Effective Time: 20240118, Effective Date: 2024...   \n",
       "2  Brand Name: Omeprazole, Sodium bicarbonate, Ge...   \n",
       "3  Brand Name: Diltiazem Hydrochloride Extended-R...   \n",
       "4  Brand Name: FLUDROCORTISONE ACETATE, Generic N...   \n",
       "\n",
       "                                   uuid  \n",
       "0  a1f0d44f-d419-413e-b797-00dac391d9f3  \n",
       "1  7f3ffb22-9de3-4da0-8e3f-a7bfd0559439  \n",
       "2  f77124f7-7b23-4f9d-a60d-ce0b537aca7b  \n",
       "3  948f7a14-2725-4f12-8159-c75761e677ec  \n",
       "4  e2921711-6b00-431f-bcbd-f2b7aa8252ed  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:23.026589Z",
     "iopub.status.busy": "2025-01-11T17:37:23.026278Z",
     "iopub.status.idle": "2025-01-11T17:37:23.052044Z",
     "shell.execute_reply": "2025-01-11T17:37:23.050610Z",
     "shell.execute_reply.started": "2025-01-11T17:37:23.026558Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brand Name: Bismuth Stibium, Generic Name: BISMUTH STIBIUM, Manufacturer Name: Uriel Pharmacy Inc., Product Type: HUMAN OTC DRUG, Route: TOPICAL, Effective Time: 20240122, Effective Date: 2024-01-22, Active Ingredient: Active Ingredients: 100 gm contains: 25 gm Allium sativa (Garlic) 1X, 25 gm Chelidonium (Greater celandine) 1X, 25 gm Curcuma (Turmeric) 1X, 25 gm Thuja (American arborvitae) 1X, 20 gm Bismuth 2X, 20 gm Stibium met. (Antimony) 2X, Warnings: Warnings: FOR EXTERNAL USE ONLY. Claims based on traditional homeopathic practice, not accepted medical evidence. Not FDA evaluated. Do not use if allergic to any ingredient. Consult a doctor before use for serious conditions, if conditions worsen or persist, or accidental ingestion occurs. If pregnant or nursing, consult a doctor before use. Avoid contact with eyes. Do not use if safety seal is broken or missing., Indications and Usage: Directions: FOR TOPICAL USE ONLY., Purpose: Use: Temporary relief of warts., Dosage and Administration: Apply once or twice daily to warts. Under age 2: Consult a doctor, Keep Out of Reach of Children: KEEP OUT OF REACH OF CHILDREN., Inactive Ingredient: Inactive Ingredients: White petrolatum, Lanolin, Mineral oil, Glyceryl monostearate, Sorbic acid, Tea tree oil, Grapefruit seed extract \"prepared using rhythmical processes\", Questions: Questions? Call 866.642.2858 Made with care by Uriel, East Troy, WI 53120 shopuriel.com Lot:, SPL Product Data Elements: Bismuth Stibium Bismuth Stibium PETROLATUM LANOLIN MINERAL OIL GLYCERYL MONOSTEARATE SORBIC ACID CITRUS PARADISI SEED GARLIC GARLIC CHELIDONIUM MAJUS CHELIDONIUM MAJUS TURMERIC TURMERIC THUJA OCCIDENTALIS WHOLE THUJA OCCIDENTALIS WHOLE BISMUTH BISMUTH ANTIMONY ANTIMONY TEA TREE OIL, Package Label Principal Display Panel: Bismuth Stibium Ointment'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:23.055698Z",
     "iopub.status.busy": "2025-01-11T17:37:23.055363Z",
     "iopub.status.idle": "2025-01-11T17:37:37.268124Z",
     "shell.execute_reply": "2025-01-11T17:37:37.266856Z",
     "shell.execute_reply.started": "2025-01-11T17:37:23.055667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c17b0c16a224618a07df0820a5cff12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd808e2873514a5a88774b67d1685940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dca4661699a4f5ea4ed176e718f1f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2923dbe75b43fab99680f078215f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce67b2ab36b4b38ba91c2921bfba7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7da53c660bf45a880d40b25712355c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8e0f22f5124fd9a7aa85156806a148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8a46c18ba24b6a84c646be85597a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37df2217406a4a07b542d90c9c503fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d06dfb378645ab96f5735467ff5129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2850adba7df422cb71c781e0ce6c6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114497385e4e46348f7c0fa9a2952a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a38566cf76c4669bde60877019e569e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1e0cb2c2ce4be68c385aa2e0079d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9f70d458d1464496a76f35e338c0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd64e341e942484ab1943aab00a6f7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcad93a3bcf4787a3379d88f102a65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91e4f7b0f0a4978b351ff091fab3be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c1749421a947da816ee0804e12814d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72518945e604a73ae220ebea625b82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c326dbc58316457aaa3b3398b980e3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbb8ab49d364c498d63fc59bd141369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5f6edb8c204a6ebbd1ac79649a7ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01f0658ebda4858a178b7eb880c3c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87d46912e5d4d1eb840ba933257e63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc62ba5e72a4f918ffdde5a05430756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaa9dc2169f42b1b28abbf5f8c20a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6d58a5af86438a81e31701f51f0e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a150dddced51422b87bb4c533a5a510f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf7a3403c0043948ad04a40be3fd8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a072af330966464ca49dc9669fa3b094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec43c93dbb154c7f8e26b481afcdc168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0deae81b608242c1ba709484c8c937aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9f36e23ff04c7aa3bee687504efb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a1ddb2af5a464ba9eb87ffd7e8a5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098377a062a1442982ee48fcad051559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dfd1b986f24b139916f40d52f4796d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb65056cb9846a28da52cdfc77c28e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be62d8874d1a4b2abcfd9e92a1f6505b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810d973fbc7f41a885fb08fcc32c5f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22219aa59ec04e1f8c30d92f9f2bf993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ae50c2389a4c219c1943df9764d78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da54f61bb4be48488228d42fdc0478d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5b3847c6394553ac58cf14e19a603f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26635be759aa44c59eb892fde35e4bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5f8ea5c789405abe31f2a3f7f8027c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1c06d0f1e8446f83317c1064327648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ed50ef182849d4a2fe009948d2f8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5869cc24d24643a4a097e4602043af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a470c1508684e9aaa58e797d2b09ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa012561b30411083b14e86a35527c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084d5be7debe495fa77731a83c4bcd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6aab3927a34d7c857a697605818b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7500cb4d3ab04867be05cce59222501d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ed7db9cf3e4f949bb3afe5ffa58f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bf911a1d974ec59e7b89fc6bc87338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965ea44a13ca4442ae67a2811d46622b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32de1e82faac49738f0f9f5bae702464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef500c73a98a473088c2628b3c588865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b213a55ef86d4ad7bd1eec197a037f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983477fda5964ce8bdec26eb66157c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2042764eefe4445a86c82986c584fd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4abd096c7124d96a54cd2eba5658c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0427dcc374548b1b837b466943cd511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c545820666c4b41bd209d91272b46eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9a0ef646f048e7ba6325f221a09566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ddd4790a8948f2b31d391822f23b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f7ef1f1b61469384aa9b5455d700b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf6c67eaca44dbd82dbd714487c68f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4eab5b6cca34c07af6b4944ff36bf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a66ad86b724ecdbf3fcf1c425668ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7621ac5001b648d596143f8d617feda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1780c4e00e4f439d8b02af06361e5ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c1da67dda647deaa8b0da39309d2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99bf8f5331045e1bdf86e79332bc94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1950fa5ecd664098b70f95ec4f73c972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb35b6b71394511abd2d61173024ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322ee009a1f243f3bd4975f41ffb8861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce402af06ac846f1ab5ab9a7b819805f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fba5855190d43a7815fec68bff23cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555f7129544c4a18993e7bcb0b6fb695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4fdb697ded4c77aa44702c1529bb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b310447a6940d4961fc8c5498ccdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b379c70973b34d6c912adb22624f4523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739ec89957504c5394ba75698badaec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe4247b2a044c75a35dd72244af591d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07d32af952e4268a1151bdf093ee9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ec7da967124666bdbd81a6331fba41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfaffc4f25c40f49290384d663bad62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3a254f67dd48e2892ff32d30b432b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83712830ed14c9eb55f90d437ee4ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff65f1dee8440b8b99b66a2be981048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a691112b5a410b93577133daa71fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e466e6dd594650b2ab2d7dbb8547cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61373d467ad34019af6104b2dc03fed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f23fb72ed44fb2b6a7d1b9010721bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bb88fd190c46cbaea59408954c8637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899fff3c897e4e8590608a7d50d9f413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a068c47129cd4280a04d9ef9078bc36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da75b6bf25dd474dbf7a5d39fa09b511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3225e86307dd42a1a0f984aa9d66c691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a316a0763942d491efa18b98f6cd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14131b2b67e2476ba1ddba5ee135c988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2e8c7a21534f789e0ecdc0a44fbfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef2781918e34e2c9450d96f06f1f583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c08a5605284645828c3642381a6bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb53baf05af2432e80ad05807fd40a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f64f1f5e70452c946307a5847f1f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0eea88c96d341f69bd6d78bc9bd0e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4c29bc198e4b6caf78d15fe3bda23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897175a34e9e42c7bbe778f139865668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for the context column\n",
    "processed_df['embeddings'] = processed_df['chunk'].apply(lambda x: model.encode(x).tolist())\n",
    "\n",
    "# Save embeddings for later use\n",
    "processed_df.to_parquet(\"data_with_embeddings_final.parquet\", index=False)\n",
    "print(\"Data with embeddings saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.270404Z",
     "iopub.status.busy": "2025-01-11T17:37:37.269984Z",
     "iopub.status.idle": "2025-01-11T17:37:37.279476Z",
     "shell.execute_reply": "2025-01-11T17:37:37.278274Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.270369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "embeddings = np.array(processed_df['embeddings'].tolist(), dtype='float32')\n",
    "\n",
    "# Create a FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(index, \"faiss_index_final.bin\")\n",
    "print(\"FAISS index saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.281267Z",
     "iopub.status.busy": "2025-01-11T17:37:37.280904Z",
     "iopub.status.idle": "2025-01-11T17:37:37.311730Z",
     "shell.execute_reply": "2025-01-11T17:37:37.310602Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.281235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "def generate_answer_with_context_t5(query, context):\n",
    "    model_name = \"t5-large\"  # or \"t5-base\", \"t5-large\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_length=100, num_beams=4, early_stopping=True)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.313448Z",
     "iopub.status.busy": "2025-01-11T17:37:37.313072Z",
     "iopub.status.idle": "2025-01-11T17:37:37.354334Z",
     "shell.execute_reply": "2025-01-11T17:37:37.353289Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.313410Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def generate_answer_with_context_gpt2(query, context):\n",
    "    model_name = \"gpt2\"  # You can use \"gpt2-medium\", \"gpt2-large\" for larger models\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    # Increase max_length to a higher value, ensuring it's within the model's token limit\n",
    "    max_input_length = 1024  # Ensure this is within the model's max token limit\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n",
    "    \n",
    "    # Set max_new_tokens to control the length of the generated answer\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_new_tokens=150, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7)\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remove the prompt part from the output and return the answer\n",
    "    answer = generated_text[len(input_text):].strip()\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.356011Z",
     "iopub.status.busy": "2025-01-11T17:37:37.355469Z",
     "iopub.status.idle": "2025-01-11T17:37:37.363172Z",
     "shell.execute_reply": "2025-01-11T17:37:37.361893Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.355976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "def generate_answer_with_context_bert(query, context):\n",
    "    model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "    model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Prepare the input text for BERT\n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Print the tokenized input to check if the context and question are properly encoded\n",
    "    # print(\"Tokenized Input:\", inputs)\n",
    "\n",
    "    # Run the model to get start and end logits\n",
    "    outputs = model(**inputs)\n",
    "    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "    # Print the logits to see what the model is predicting\n",
    "    # print(\"Start Scores:\", start_scores)\n",
    "    # print(\"End Scores:\", end_scores)\n",
    "\n",
    "    # Get the most likely start and end positions\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "    # Check if the answer span is valid\n",
    "    if answer_start >= answer_end:\n",
    "        print(\"No valid answer found.\")\n",
    "        return \"No valid answer found.\"\n",
    "\n",
    "    # Decode the answer (removes [CLS], [SEP] tokens and gives you the answer span)\n",
    "    answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end], skip_special_tokens=True)\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.364963Z",
     "iopub.status.busy": "2025-01-11T17:37:37.364478Z",
     "iopub.status.idle": "2025-01-11T17:37:37.400206Z",
     "shell.execute_reply": "2025-01-11T17:37:37.398800Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.364930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizer\n",
    "import torch\n",
    "\n",
    "def generate_answer_with_context_distilbert(query, context):\n",
    "    model_name = \"distilbert-base-uncased-distilled-squad\"\n",
    "    model = DistilBertForQuestionAnswering.from_pretrained(model_name)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores) + 1\n",
    "    answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end])\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.401674Z",
     "iopub.status.busy": "2025-01-11T17:37:37.401278Z",
     "iopub.status.idle": "2025-01-11T17:37:37.409191Z",
     "shell.execute_reply": "2025-01-11T17:37:37.407974Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.401631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def generate_answer_with_context_gemini(query, context):\n",
    "    # Initialize Google Generative AI model\n",
    "    genai.configure(api_key=\"AIzaSyAMCnx5Wde22yIsRL53lB20FETVkCXe2Ws\")\n",
    "    # gemini_model = genai.GenerativeModel('gemini-pro')\n",
    "    gemini_model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "    \n",
    "    # Construct the prompt\n",
    "    prompt = f\"Given the following context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    try:\n",
    "        # Use the correct method to generate an answer, check if `generate_content` or `generate` is available\n",
    "        answer = gemini_model.generate_content(prompt)  # Correct method usage\n",
    "        # print(answer.text)\n",
    "\n",
    "        \n",
    "        # Print and return the answer\n",
    "        print(\"Generated Answer:\")\n",
    "        return answer.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error while generating content: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.410792Z",
     "iopub.status.busy": "2025-01-11T17:37:37.410355Z",
     "iopub.status.idle": "2025-01-11T17:37:37.438484Z",
     "shell.execute_reply": "2025-01-11T17:37:37.437217Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.410736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BloomForCausalLM, BloomTokenizerFast\n",
    "\n",
    "def generate_answer_with_context_bloom(query, context):\n",
    "    model_name = \"bigscience/bloom-560m\"\n",
    "    model = BloomForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = BloomTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    # Create the prompt\n",
    "    input_text = f\"Given the following context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=True)\n",
    "\n",
    "    # Generate the response\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_new_tokens=100)  # Control only new token generation\n",
    "\n",
    "    # Decode the generated tokens to text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_text = generated_text.split('Question: ')[-1]\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.440186Z",
     "iopub.status.busy": "2025-01-11T17:37:37.439717Z",
     "iopub.status.idle": "2025-01-11T17:37:37.450887Z",
     "shell.execute_reply": "2025-01-11T17:37:37.449736Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.440138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "def generate_answer_with_context_distilgpt2(query, context):\n",
    "    model_name = \"distilgpt2\"\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_new_tokens=150, temperature=0.9)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_text = generated_text.split('Question: ')[-1]\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.452419Z",
     "iopub.status.busy": "2025-01-11T17:37:37.452029Z",
     "iopub.status.idle": "2025-01-11T17:37:37.481195Z",
     "shell.execute_reply": "2025-01-11T17:37:37.479932Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.452389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import ElectraForQuestionAnswering, ElectraTokenizer\n",
    "import torch\n",
    "\n",
    "def generate_answer_with_context_electra(query, context):\n",
    "    model_name = \"google/electra-small-discriminator\"\n",
    "    model = ElectraForQuestionAnswering.from_pretrained(model_name)\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores) + 1\n",
    "    answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end])\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.482635Z",
     "iopub.status.busy": "2025-01-11T17:37:37.482339Z",
     "iopub.status.idle": "2025-01-11T17:37:37.501538Z",
     "shell.execute_reply": "2025-01-11T17:37:37.500258Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.482607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import ReformerForSequenceClassification, ReformerTokenizer\n",
    "\n",
    "def generate_answer_with_context_reformer(query, context):\n",
    "    model_name = \"google/reformer-enwik8\"\n",
    "    model = ReformerForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = ReformerTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], max_length=150)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:37:37.503366Z",
     "iopub.status.busy": "2025-01-11T17:37:37.502894Z",
     "iopub.status.idle": "2025-01-11T17:37:37.508309Z",
     "shell.execute_reply": "2025-01-11T17:37:37.507168Z",
     "shell.execute_reply.started": "2025-01-11T17:37:37.503318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"REPLICATE\"] = \"r8_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:45:06.170769Z",
     "iopub.status.busy": "2025-01-11T17:45:06.170376Z",
     "iopub.status.idle": "2025-01-11T17:45:06.177435Z",
     "shell.execute_reply": "2025-01-11T17:45:06.175584Z",
     "shell.execute_reply.started": "2025-01-11T17:45:06.170735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "\n",
    "\n",
    "def generate_answer_with_context_LAMA_2(query, context):\n",
    "   \n",
    "    input_text = f\"Context: {context}\\nQuestion: {query}\"\n",
    "    input = {\n",
    "    \"top_p\": 1,\n",
    "    \"prompt\": input_text,\n",
    "    \"temperature\": 0.75,\n",
    "    \"max_new_tokens\": 800\n",
    "    }\n",
    "    \n",
    "    generated_text= \"\"\n",
    "    for event in replicate.stream(\n",
    "        \"meta/llama-2-7b-chat\",\n",
    "        input=input\n",
    "    ):\n",
    "        # print(event, end=\"\")\n",
    "        generated_text += str(event)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:38:38.847342Z",
     "iopub.status.busy": "2025-01-11T17:38:38.846966Z",
     "iopub.status.idle": "2025-01-11T17:38:38.852036Z",
     "shell.execute_reply": "2025-01-11T17:38:38.850861Z",
     "shell.execute_reply.started": "2025-01-11T17:38:38.847306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import replicate\n",
    "\n",
    "# input = {\n",
    "#     \"top_p\": 1,\n",
    "#     \"prompt\": \"Tell me how to tailor a men's suit so I look fashionable.\",\n",
    "#     \"temperature\": 0.75,\n",
    "#     \"max_new_tokens\": 800\n",
    "# }\n",
    "\n",
    "# for event in replicate.stream(\n",
    "#     \"meta/llama-2-7b-chat\",\n",
    "#     input=input\n",
    "# ):\n",
    "#     print(event, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T18:20:27.814570Z",
     "iopub.status.busy": "2025-01-11T18:20:27.814026Z",
     "iopub.status.idle": "2025-01-11T18:22:07.172784Z",
     "shell.execute_reply": "2025-01-11T18:22:07.171336Z",
     "shell.execute_reply.started": "2025-01-11T18:20:27.814528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7395a3970a642cc8327a05bc777c0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 model\n",
      "It is a natural compound that is used to treat wart, ulcers, and other conditions. It has been used for centuries to relieve warty, sore throats, to prevent the spread of diseases, as well as to cure the common cold.\n",
      "Bismutum St.ibum is an alkaloid found in the bark of the tree of B. stibus. The bark is composed of a mixture of two parts: the alkaline and the insoluble part. Bistum st.bismum contains a compound called bismulose, which is found naturally in bark. This compound is known as bistulosulfate. In the United States, it is also known by the name bicarbonate\n",
      "------------------------\n",
      "T5 model\n",
      "GARLIC CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJ\n",
      "------------------------\n",
      "bloom model\n",
      "what is Bismuth Stibium ?\n",
      "Answer: Bismuth Stibium is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived\n",
      "------------------------\n",
      "Generated Answer:\n",
      "GEMINI model\n",
      "Bismuth Stibium is a homeopathic ointment marketed for the temporary relief of warts.  It contains Bismuth and Stibium (Antimony) along with several other homeopathic ingredients like garlic, greater celandine, turmeric, and American arborvitae.  It is for topical use only and is not FDA evaluated.\n",
      "\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electra model\n",
      ": bismuth stibium, generic name : bismut\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilgpt2 model\n",
      "what is Bismuth Stibium?\n",
      "Answer: Bismuth Stibium is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is a compound of the Bismuth Stibium, which is\n",
      "------------------------\n",
      "LAMA-2 model\n",
      " Hello! I'm here to help you with your question. Bismuth Stibium is a topical ointment that contains various homeopathic ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, Stibium met. (Antimony), and others. It is manufactured by Uriel Pharmacy Inc. and is designed to provide temporary relief from warts.\n",
      "\n",
      "However, I must inform you that the safety and effectiveness of Bismuth Stibium have not been evaluated by the FDA, and its claims are based on traditional homeopathic practice rather than accepted medical evidence. As such, it is important to consult with a doctor before using this product, especially if you have a serious medical condition or accidental ingestion occurs.\n",
      "\n",
      "Additionally, it is important to follow the instructions for use carefully and avoid contact with the eyes. If you have any questions or concerns, please call 866.642.2858 for more information.\n",
      "\n",
      "In summary, Bismuth Stibium is a topical ointment that contains various homeopathic ingredients and is designed to provide temporary relief from warts. However, its safety and effectiveness have not been evaluated by the FDA, and it is important to consult with a doctor before using it.\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index(\"faiss_index_final.bin\")\n",
    "\n",
    "# Example query\n",
    "query = \"what is Bismuth Stibium ?\"\n",
    "query_embedding = model.encode(query).astype('float32').reshape(1, -1)\n",
    "\n",
    "# Retrieve the top 5 most relevant contexts\n",
    "distances, indices = index.search(query_embedding, 5)\n",
    "\n",
    "# Extract the relevant contexts\n",
    "relevant_contexts = processed_df.iloc[indices[0]]['chunk'].tolist()\n",
    "\n",
    "# print('relevent context : ',relevant_contexts)\n",
    "context = relevant_contexts[0]\n",
    "\n",
    "# For GPT-2\n",
    "generated_answer = generate_answer_with_context_gpt2(query, context)\n",
    "print(\"GPT-2 model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# For T5\n",
    "generated_answer = generate_answer_with_context_t5(query, context)\n",
    "print(\"T5 model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# For BLOOM\n",
    "generated_answer = generate_answer_with_context_bloom(query, context)\n",
    "print(\"bloom model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "# For GEMINI\n",
    "generated_answer = generate_answer_with_context_gemini(query, context)\n",
    "print(\"GEMINI model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# For GEMINI\n",
    "# generated_answer = generate_answer_with_context_reformer(query, context)\n",
    "# print(\"REFORMER model\")\n",
    "# print(generated_answer)\n",
    "# print(\"------------------------\")\n",
    "\n",
    "# For Electra\n",
    "generated_answer = generate_answer_with_context_electra(query, context)\n",
    "print(\"Electra model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "\n",
    "# For Distilgpt2\n",
    "generated_answer = generate_answer_with_context_distilgpt2(query, context)\n",
    "print(\"Distilgpt2 model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "# For LLAMA 2\n",
    "generated_answer = generate_answer_with_context_LAMA_2(query, context)\n",
    "print(\"LAMA-2 model\")\n",
    "print(generated_answer)\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T17:45:38.139195Z",
     "iopub.status.busy": "2025-01-11T17:45:38.138693Z",
     "iopub.status.idle": "2025-01-11T17:47:18.511793Z",
     "shell.execute_reply": "2025-01-11T17:47:18.510578Z",
     "shell.execute_reply.started": "2025-01-11T17:45:38.139156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\n",
      "Evaluating GPT-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-2 Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: This product is a topical product that is used to treat wart, ulcers, and other skin conditions. It is also used for topical use to prevent or treat other conditions such as acne, psoriasis, eczema, rashes, dry skin, skin cancer, etc.\n",
      "What is the difference between Bistuth and Bactulose? BISTUTH is an antiseptic that has been used in the treatment of psoriatic ulcerative colitis, acne vulgaris, dermatitis and psorsitis. BACTULOSE is another topical antisera that was used as a treatment for psorectal ulicosis. The difference is that BIS is not a preservative. This is because B\n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.28723404255319157, 'rouge2': 0.053763440860215055, 'rougeL': 0.1595744680851064, 'bleu': 0.32030896835479866, 'exact_match': 0, 'f1': 0.20437956204379565, 'execution_time': 11.196508884429932}\n",
      "\n",
      "Evaluating T5...\n",
      "\n",
      "T5 Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: GARLIC CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJUS CHELIDONIUM MAJ\n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.03418803418803419, 'rouge2': 0.017391304347826087, 'rougeL': 0.03418803418803419, 'bleu': 0, 'exact_match': 0, 'f1': 0.025641025641025644, 'execution_time': 42.285906076431274}\n",
      "\n",
      "Evaluating BERT...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c969c1e9164c1d9afe92eaed27abfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbbcdf207a34abdabcb9f065989d50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15107fef43064fe5a2b123993cd7956c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20a9218b5004785a0c7944dd57cfe40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0491a5da08df4ecd910753e852e654a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: \n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0, 'bleu': 0, 'exact_match': 0, 'f1': 0, 'execution_time': 12.817095756530762}\n",
      "\n",
      "Evaluating DistilBERT...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27ed7bc5af54b38bf82481b1d6d25bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c55fd9c2ed4fefa13c403e903a1e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a204632f2e8e4ff2a4843ba08fb3c0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bea34f5e6a40e3809a9e5d8fa0ee8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4d6eb9a10240549a532c57ff5a8810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DistilBERT Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: \n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0, 'bleu': 0, 'exact_match': 0, 'f1': 0, 'execution_time': 4.07785701751709}\n",
      "\n",
      "Evaluating BLOOM...\n",
      "\n",
      "BLOOM Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer: What is Bismuth Stibium?\n",
      "Answer: Bismuth Stibium is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived from the roots of the herb Bismuth. It is a natural product derived\n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.24175824175824176, 'rouge2': 0.044444444444444446, 'rougeL': 0.2087912087912088, 'bleu': 0.035371965931008, 'exact_match': 0, 'f1': 0.17582417582417584, 'execution_time': 26.47500443458557}\n",
      "\n",
      "Evaluating LLAMA-2...\n",
      "\n",
      "LLAMA-2 Results for Question: What is Bismuth Stibium?\n",
      "Predicted Answer:  Hello! I'm here to help you with your question. Bismuth Stibium is a topical ointment that is used to treat warts. It contains several homeopathic ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium met. (Antimony). These ingredients are said to have antiviral and ant-inflammatory properties, which may help to reduce the size and number of warts on the skin.\n",
      "\n",
      "It's important to note that while Bismuth Stibium may be effective in treating warts, it is not a cure-all and may not work for everyone. It's also important to follow the instructions for use carefully and to consult a doctor before use if you have any concerns or if your symptoms persist or worsen.\n",
      "\n",
      "In terms of safety, Bismuth Stibium is generally considered safe to use when used as directed. However, it's important to avoid using it near the eyes or on broken skin, and to consult a doctor before use if you are pregnant or nursing.\n",
      "\n",
      "I hope this information is helpful! Let me know if you have any other questions.\n",
      "Reference Answer: Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.\n",
      "Metrics: {'rouge1': 0.4115523465703971, 'rouge2': 0.1890909090909091, 'rougeL': 0.28158844765342966, 'bleu': 0.14146354640523665, 'exact_match': 0, 'f1': 0.425531914893617, 'execution_time': 2.4321658611297607}\n",
      "\n",
      "Final Evaluation Results:\n",
      "                  GPT-2       T5     BERT  DistilBERT    BLOOM  LLAMA-2\n",
      "rouge1           0.2872   0.0342   0.0000      0.0000   0.2418   0.4116\n",
      "rouge2           0.0538   0.0174   0.0000      0.0000   0.0444   0.1891\n",
      "rougeL           0.1596   0.0342   0.0000      0.0000   0.2088   0.2816\n",
      "bleu             0.3203   0.0000   0.0000      0.0000   0.0354   0.1415\n",
      "exact_match      0.0000   0.0000   0.0000      0.0000   0.0000   0.0000\n",
      "f1               0.2044   0.0256   0.0000      0.0000   0.1758   0.4255\n",
      "execution_time  11.1965  42.2859  12.8171      4.0779  26.4750   2.4322\n",
      "\n",
      "Results saved to 'rag_evaluation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')  # Required for BLEU score\n",
    "\n",
    "# First, let's define our test dataset with some sample questions and reference answers\n",
    "test_data = [\n",
    "    {\n",
    "        'question': 'What is Bismuth Stibium?',\n",
    "        'context': context,  # Your existing context\n",
    "        'reference_answer': 'Bismuth Stibium is a human over-the-counter (OTC) drug manufactured by Uriel Pharmacy Inc., used topically for the temporary relief of warts. It contains a blend of active ingredients, including Allium sativa (Garlic), Chelidonium (Greater celandine), Curcuma (Turmeric), Thuja (American arborvitae), Bismuth, and Stibium (Antimony). The product is for external use only and is marketed as a homeopathic remedy based on traditional practices, though it is not FDA evaluated. The ointment is applied once or twice daily to warts, with special instructions to consult a doctor for children under age 2.'\n",
    "    },\n",
    "    # Add more test cases if you have them\n",
    "]\n",
    "\n",
    "# Keep your existing model functions\n",
    "models = {\n",
    "    'GPT-2': generate_answer_with_context_gpt2,\n",
    "    'T5': generate_answer_with_context_t5,\n",
    "    # 'BERT': generate_answer_with_context_bert,\n",
    "    # 'DistilBERT': generate_answer_with_context_distilbert,\n",
    "    'BLOOM': generate_answer_with_context_bloom,\n",
    "    'LLAMA-2': generate_answer_with_context_LAMA_2\n",
    "}\n",
    "\n",
    "def evaluate_single_answer(predicted, reference):\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # ROUGE scores\n",
    "    rouge_scores = scorer.score(predicted, reference)\n",
    "    \n",
    "    # BLEU score\n",
    "    ref_tokens = [reference.split()]\n",
    "    pred_tokens = predicted.split()\n",
    "    try:\n",
    "        bleu = sentence_bleu(ref_tokens, pred_tokens)\n",
    "    except:\n",
    "        bleu = 0\n",
    "    \n",
    "    # Exact Match\n",
    "    exact_match = 1 if predicted.lower().strip() == reference.lower().strip() else 0\n",
    "    \n",
    "    # F1 Score\n",
    "    pred_words = set(predicted.lower().split())\n",
    "    ref_words = set(reference.lower().split())\n",
    "    \n",
    "    precision = len(pred_words & ref_words) / len(pred_words) if pred_words else 0\n",
    "    recall = len(pred_words & ref_words) / len(ref_words) if ref_words else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0\n",
    "    \n",
    "    return {\n",
    "        'rouge1': rouge_scores['rouge1'].fmeasure,\n",
    "        'rouge2': rouge_scores['rouge2'].fmeasure,\n",
    "        'rougeL': rouge_scores['rougeL'].fmeasure,\n",
    "        'bleu': bleu,\n",
    "        'exact_match': exact_match,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "def evaluate_model(model_name, model_func, test_data):\n",
    "    all_metrics = []\n",
    "    execution_times = []\n",
    "    \n",
    "    for test_case in test_data:\n",
    "        # Measure execution time\n",
    "        start_time = time.time()\n",
    "        predicted_answer = model_func(test_case['question'], test_case['context'])\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = evaluate_single_answer(predicted_answer, test_case['reference_answer'])\n",
    "        metrics['execution_time'] = execution_time\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        # Print individual results\n",
    "        print(f\"\\n{model_name} Results for Question: {test_case['question']}\")\n",
    "        print(f\"Predicted Answer: {predicted_answer}\")\n",
    "        print(f\"Reference Answer: {test_case['reference_answer']}\")\n",
    "        print(f\"Metrics: {metrics}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_metrics = {\n",
    "        metric: np.mean([m[metric] for m in all_metrics])\n",
    "        for metric in all_metrics[0].keys()\n",
    "    }\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Run evaluation for all models\n",
    "results = {}\n",
    "for model_name, model_func in models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    try:\n",
    "        results[model_name] = evaluate_model(model_name, model_func, test_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Create final report\n",
    "df_results = pd.DataFrame(results).round(4)\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(df_results)\n",
    "\n",
    "# Save results to CSV\n",
    "df_results.to_csv('rag_evaluation_results.csv')\n",
    "print(\"\\nResults saved to 'rag_evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6444752,
     "sourceId": 10401121,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
